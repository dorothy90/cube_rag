#!/usr/bin/env python3
"""
CSV ë°ì´í„° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
DirectLLMSummarizerë¥¼ ì‚¬ìš©í•˜ì—¬ ì±„íŒ… ë©”ì‹œì§€ ì£¼ì œë³„ ìš”ì•½
"""

import pandas as pd
import os
import sys
from datetime import datetime
import logging
import argparse

# Backend ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
backend_path = os.path.join(os.path.dirname(__file__), 'backend')
sys.path.append(backend_path)

try:
    from direct_llm_summarizer import DirectLLMSummarizer
except ImportError as e:
    print(f"âŒ DirectLLMSummarizer ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    print("ë°±ì—”ë“œ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def load_csv_data(csv_path: str) -> pd.DataFrame:
    """CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    try:
        df = pd.read_csv(csv_path)
        logger.info(f"ğŸ“Š CSV ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰")
        return df
    except Exception as e:
        logger.error(f"âŒ CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def convert_to_message_format(df: pd.DataFrame) -> list:
    """DataFrameì„ DirectLLMSummarizerì—ì„œ ì‚¬ìš©í•˜ëŠ” ë©”ì‹œì§€ í˜•íƒœë¡œ ë³€í™˜"""
    messages = []
    
    for _, row in df.iterrows():
        # content í•„ë“œì—ì„œ ì‹¤ì œ ë©”ì‹œì§€ ë‚´ìš© ì¶”ì¶œ
        content = str(row.get('content', ''))
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ ê²½ìš° ë©”ì‹œì§€ ë‚´ìš©ë§Œ ì¶”ì¶œ
        if ' ' in content and any(char.isdigit() for char in content[:20]):
            # ì¼ë°˜ì ìœ¼ë¡œ "24. 9. 2. ì˜¤í›„ 12:27 ì‹¤ì œë©”ì‹œì§€ë‚´ìš©" í˜•íƒœ
            parts = content.split(' ', 4)  # ë‚ ì§œ+ì‹œê°„ ë¶€ë¶„ì„ ê±´ë„ˆë›°ê¸°
            if len(parts) > 4:
                content = parts[4]
            elif len(parts) > 3:
                content = parts[3]
        
        # ë¹ˆ ë©”ì‹œì§€ë‚˜ ë„ˆë¬´ ì§§ì€ ë©”ì‹œì§€ í•„í„°ë§
        content = content.strip()
        if len(content) < 3:
            continue
            
        message = {
            'content': content,
            'reaction_count': int(row.get('reaction_count', 0)),
            'message_id': str(row.get('message_id', '')),
            'timestamp': str(row.get('timestamp', '')),
            'nickname': str(row.get('nickname', ''))
        }
        messages.append(message)
    
    logger.info(f"ğŸ“ ë©”ì‹œì§€ ë³€í™˜ ì™„ë£Œ: {len(messages)}ê°œ")
    return messages

def analyze_data(csv_path: str, output_dir: str = "analysis_results", from_date: str = None, to_date: str = None, email: str = None, print_only: bool = False):
    """CSV ë°ì´í„° ë¶„ì„ ì‹¤í–‰"""
    if print_only:
        # ì „ì²˜ë¦¬ ì—†ì´ ì¸ìë§Œ ì¶œë ¥í•˜ê³  ì¦‰ì‹œ ì¢…ë£Œ
        print("[PRINT-ONLY] analyze_data.py invoked")
        print(f"from_date={from_date}")
        print(f"to_date={to_date}")
        print(f"email={email}")
        return

    # CSV ë°ì´í„° ë¡œë“œ
    df = load_csv_data(csv_path)
    if df is None:
        return
    
    print(f"\nğŸ“Š ë°ì´í„° ê°œìš”:")
    print(f"  - ì „ì²´ ë©”ì‹œì§€: {len(df)}ê°œ")
    print(f"  - ì»¬ëŸ¼: {list(df.columns)}")
    print(f"  - ê¸°ê°„: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
    
    # ë©”ì‹œì§€ í˜•íƒœë¡œ ë³€í™˜
    messages = convert_to_message_format(df)
    
    if not messages:
        print("âŒ ë¶„ì„í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ” í•„í„°ë§ëœ ë©”ì‹œì§€: {len(messages)}ê°œ")
    print(f"ì˜ˆì‹œ ë©”ì‹œì§€:")
    for i, msg in enumerate(messages[:3], 1):
        print(f"  {i}. (ğŸ‘{msg['reaction_count']}) {msg['content'][:50]}...")
    
    # DirectLLMSummarizer ì´ˆê¸°í™”
    try:
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’ ì—†ìŒ: í•˜ë“œì½”ë”© ê¸ˆì§€)
        openai_key = os.getenv('OPENAI_API_KEY')
        
        summarizer = DirectLLMSummarizer(
            openai_api_key=openai_key,
            anthropic_api_key=os.getenv('ANTHROPIC_API_KEY'),
            request_delay=1.0
        )
        
        if not summarizer.openai_client and not summarizer.anthropic_client:
            print("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            print("OPENAI_API_KEY ë˜ëŠ” ANTHROPIC_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return
        
    except Exception as e:
        print(f"âŒ DirectLLMSummarizer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # ì£¼ì œë³„ ìš”ì•½ ì‹¤í–‰
    print(f"\nğŸ¤– LLM ì£¼ì œë³„ ìš”ì•½ ì‹œì‘...")
    
    try:
        result = summarizer.summarize_messages_directly(
            messages=messages,
            max_topics=8,
            language="korean"
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ“‹ ì£¼ì œë³„ ìš”ì•½ ê²°ê³¼")
        print("="*60)
        
        stats = result['statistics']
        print(f"\nğŸ“Š ì²˜ë¦¬ í†µê³„:")
        print(f"  - ì „ì²´ ë©”ì‹œì§€: {stats['total_messages']}ê°œ")
        print(f"  - ì²˜ë¦¬ ì²­í¬: {stats['processed_chunks']}ê°œ") 
        print(f"  - ì¶”ì¶œëœ ì£¼ì œ: {stats['total_topics']}ê°œ")
        print(f"  - ë°°ì •ëœ ë©”ì‹œì§€: {stats.get('assigned_messages', 'N/A')}ê°œ")
        print(f"  - ë¯¸ë°°ì • ë©”ì‹œì§€: {stats.get('unassigned_messages', 'N/A')}ê°œ")
        print(f"  - ê³ ë°˜ì‘ ë¯¸ë°°ì •: {stats.get('high_reaction_unassigned', 'N/A')}ê°œ")
        print(f"  - ì‚¬ìš©ëœ LLM: {stats['llm_provider']}")
        print(f"  - ì²˜ë¦¬ ì‹œê°„: {stats['processing_time']}")
        
        print(f"\nğŸ“Œ ì£¼ì œë³„ ìƒì„¸ ë¶„ì„:")
        for i, topic in enumerate(result['topics'], 1):
            print(f"\n{i}. ğŸ“‚ {topic['topic_name']}")
            print(f"   ğŸ’¬ {topic['summary']}")
            print(f"   ğŸ“Š ê´€ë ¨ ë©”ì‹œì§€: ì•½ {topic.get('message_count', 0)}ê°œ")
            
            if topic.get('keywords'):
                print(f"   ğŸ·ï¸  í‚¤ì›Œë“œ: {', '.join(topic['keywords'])}")
            
            # ìƒìœ„ ë©”ì‹œì§€ ì¶œë ¥
            if topic.get('top_messages'):
                print(f"   ğŸ”¥ ìƒìœ„ ë©”ì‹œì§€ (ë°˜ì‘ ìˆ˜ ê¸°ì¤€):")
                for j, msg in enumerate(topic['top_messages'], 1):
                    content = msg['content'][:80] + "..." if len(msg['content']) > 80 else msg['content']
                    print(f"      {j}. (ğŸ‘ {msg['reaction_count']}) {content}")
        
        # ë¯¸ë°°ì •ëœ ê³ ë°˜ì‘ ë©”ì‹œì§€ ì¶œë ¥
        if result.get('unassigned_high_reaction_messages'):
            print(f"\nğŸš¨ ë¯¸ë°°ì •ëœ ê³ ë°˜ì‘ ë©”ì‹œì§€ (reaction_count > 2):")
            print(f"ì´ {len(result['unassigned_high_reaction_messages'])}ê°œ ë©”ì‹œì§€")
            for i, msg in enumerate(result['unassigned_high_reaction_messages'][:10], 1):  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
                content = msg['content'][:80] + "..." if len(msg['content']) > 80 else msg['content']
                print(f"  {i}. (ğŸ‘ {msg['reaction_count']}) {content}")
            
            if len(result['unassigned_high_reaction_messages']) > 10:
                print(f"  ... ë° {len(result['unassigned_high_reaction_messages']) - 10}ê°œ ë”")
        
        # ê²°ê³¼ ì €ì¥
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = os.path.join(output_dir, f"analysis_result_{timestamp}.json")
        
        summarizer.save_summary_to_file(result, output_file)
        print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_file}")
        
        # ê°„ë‹¨í•œ í†µê³„ ì •ë³´ë„ ì €ì¥
        stats_file = os.path.join(output_dir, f"analysis_stats_{timestamp}.txt")
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write("ì±„íŒ… ë©”ì‹œì§€ ë¶„ì„ ê²°ê³¼ í†µê³„\n")
            f.write("="*50 + "\n\n")
            f.write(f"ë¶„ì„ ë‚ ì§œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ì›ë³¸ CSV íŒŒì¼: {csv_path}\n")
            f.write(f"ì „ì²´ ë©”ì‹œì§€ ìˆ˜: {stats['total_messages']}ê°œ\n")
            f.write(f"ì²˜ë¦¬ ì²­í¬ ìˆ˜: {stats['processed_chunks']}ê°œ\n")
            f.write(f"ì¶”ì¶œëœ ì£¼ì œ ìˆ˜: {stats['total_topics']}ê°œ\n")
            f.write(f"ë°°ì •ëœ ë©”ì‹œì§€: {stats.get('assigned_messages', 'N/A')}ê°œ\n")
            f.write(f"ë¯¸ë°°ì • ë©”ì‹œì§€: {stats.get('unassigned_messages', 'N/A')}ê°œ\n")
            f.write(f"ê³ ë°˜ì‘ ë¯¸ë°°ì •: {stats.get('high_reaction_unassigned', 'N/A')}ê°œ\n")
            f.write(f"ì‚¬ìš©ëœ LLM: {stats['llm_provider']}\n\n")
            
            f.write("ì£¼ì œ ëª©ë¡:\n")
            f.write("-" * 30 + "\n")
            for i, topic in enumerate(result['topics'], 1):
                f.write(f"{i}. {topic['topic_name']}\n")
                f.write(f"   ìš”ì•½: {topic['summary']}\n")
                f.write(f"   í‚¤ì›Œë“œ: {', '.join(topic.get('keywords', []))}\n\n")
            
            # ë¯¸ë°°ì •ëœ ê³ ë°˜ì‘ ë©”ì‹œì§€ ì •ë³´ ì¶”ê°€
            if result.get('unassigned_high_reaction_messages'):
                f.write("ë¯¸ë°°ì •ëœ ê³ ë°˜ì‘ ë©”ì‹œì§€ (reaction_count > 2):\n")
                f.write("-" * 40 + "\n")
                for i, msg in enumerate(result['unassigned_high_reaction_messages'][:5], 1):  # ìƒìœ„ 5ê°œë§Œ ì €ì¥
                    f.write(f"{i}. (ğŸ‘ {msg['reaction_count']}) {msg['content'][:100]}...\n")
                f.write(f"\nì´ {len(result['unassigned_high_reaction_messages'])}ê°œì˜ ë¯¸ë°°ì • ê³ ë°˜ì‘ ë©”ì‹œì§€\n")
        
        print(f"ğŸ“„ í†µê³„ ì •ë³´ ì €ì¥: {stats_file}")
        print("\nâœ… ë°ì´í„° ë¶„ì„ ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"âŒ ìš”ì•½ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì±„íŒ… ë©”ì‹œì§€ ë°ì´í„° ë¶„ì„ ë° ìš”ì•½")
    parser.add_argument('--csv', dest='csv_path', default="/Users/daehwankim/cube_rag/summary/scraped_messages_293msgs_20250831_152924.csv", help='ë¶„ì„í•  CSV íŒŒì¼ ê²½ë¡œ')
    # ì˜ˆì•½ì–´ íšŒí”¼ë¥¼ ìœ„í•´ dest ì§€ì •
    parser.add_argument('--from', dest='from_date', default=None, help='ì‹œì‘ ë‚ ì§œ YYYY-MM-DD')
    parser.add_argument('--to', dest='to_date', default=None, help='ì¢…ë£Œ ë‚ ì§œ YYYY-MM-DD')
    parser.add_argument('--email', dest='email', default=None, help='ê²°ê³¼ ìˆ˜ì‹  ì´ë©”ì¼ ì£¼ì†Œ')
    parser.add_argument('--print-only', dest='print_only', action='store_true', help='ì „ì²˜ë¦¬ ì—†ì´ ì¸ìë§Œ ì¶œë ¥í•˜ê³  ì¢…ë£Œ')
    args = parser.parse_args()

    if args.print_only:
        analyze_data(args.csv_path, from_date=args.from_date, to_date=args.to_date, email=args.email, print_only=True)
        return

    print("ğŸš€ ì±„íŒ… ë©”ì‹œì§€ ë°ì´í„° ë¶„ì„ ì‹œì‘")
    print("DirectLLMSummarizerë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì œë³„ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.\n")

    csv_file = args.csv_path
    if os.path.exists(csv_file):
        print(f"ğŸ“ ë¶„ì„ íŒŒì¼: {os.path.basename(csv_file)}")
        analyze_data(csv_file, from_date=args.from_date, to_date=args.to_date, email=args.email)
    else:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_file}")

if __name__ == "__main__":
    main()